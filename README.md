# üöÄ AutoMLOps Studio

### Exploratory ML & MLOps Learning Engine

![Python 3.11](https://img.shields.io/badge/Python-3.11-3776AB?style=flat&logo=python&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?style=flat&logo=docker&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-Integrated-0194E2?style=flat&logo=mlflow&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?style=flat&logo=streamlit&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat&logo=fastapi)

O **AutoMLOps Studio** √© um projeto educacional desenvolvido de um **estudante para estudantes**. O objetivo principal √© fornecer uma ferramenta pr√°tica para quem deseja explorar o mundo do Machine Learning ou criar modelos rapidamente para prototipagem e aprendizado.

**Este projeto n√£o √© uma solu√ß√£o empresarial**, mas sim um laborat√≥rio interativo para aprender conceitos de AutoML, MLOps e Vis√£o Computacional na pr√°tica, facilitando a experimenta√ß√£o r√°pida sem a necessidade de escrever centenas de linhas de c√≥digo de infraestrutura.

Este documento serve como refer√™ncia central para todas as funcionalidades, op√ß√µes de configura√ß√£o e aprendizados t√©cnicos desenvolvidos durante a cria√ß√£o do projeto.

---

## üéØ Objetivo e Problem√°tica

Muitas vezes, aprender Machine Learning parece fragmentado entre teoria e c√≥digo complexo. Este projeto resolve isso ao centralizar:
- **Aprendizado Pr√°tico**: Entenda como o pr√©-processamento, o treinamento e o monitoramento se conectam.
- **Prototipagem R√°pida**: Teste ideias de modelos em segundos com arquivos CSV ou imagens.
- **Desmistifica√ß√£o de MLOps**: Veja na pr√°tica como o versionamento de modelos (MLflow), integra√ß√£o com DagsHub e a detec√ß√£o de desvios (Drift) funcionam em um fluxo real.

## üë• P√∫blico Alvo

- **Estudantes de Ci√™ncia de Dados**: Que querem ver a teoria aplicada em uma interface visual.
- **Curiosos e Entusiastas de ML**: Que buscam uma ferramenta √°gil para explorar datasets sem barreiras t√©cnicas.
- **Desenvolvedores em Aprendizado**: Que desejam entender como integrar modelos de ML em APIs e Dashboards de forma simplificada.

---

## ‚ú® Funcionalidades e Detalhes T√©cnicos

### 1. Gest√£o de Dados (Data Lake)
- **Upload de Dados:** Suporte para arquivos CSV.
- **Data Lake Local:** Armazenamento versionado de datasets (raw/processed).
- **Carregamento de Dados:** Sele√ß√£o de datasets e vers√µes espec√≠ficas para o workspace de trabalho.

### 2. Configura√ß√£o de Treino (AutoML)

#### 2.1. Defini√ß√£o da Tarefa
O sistema suporta os seguintes tipos de problemas de Machine Learning:
- **Classification:** Previs√£o de classes discretas (ex: fraude/n√£o fraude).
- **Regression:** Previs√£o de valores cont√≠nuos (ex: pre√ßo de im√≥veis).
- **Clustering:** Agrupamento n√£o supervisionado.
- **Time Series:** Previs√£o temporal (ex: vendas futuras).
- **Anomaly Detection:** Detec√ß√£o de outliers.

#### 2.2. Fonte do Modelo
- **AutoML Standard:** Utiliza bibliotecas padr√£o (Scikit-Learn, XGBoost, Transformers).
- **Model Registry:** Permite selecionar um modelo previamente treinado e registrado para *fine-tuning* ou re-treino.
- **Upload Local (.pkl):** Permite carregar um modelo serializado externamente.

#### 2.3. Sele√ß√£o de Modelos
- **Autom√°tico (Preset):** O sistema escolhe os melhores candidatos.
- **Manual (Selecionar):** O usu√°rio escolhe especificamente quais algoritmos testar (ex: Random Forest, XGBoost, SVM).
- **Custom Ensemble Builder:**
    - **Voting:** Combina predi√ß√µes por voto majorit√°rio (Hard) ou m√©dia de probabilidades (Soft). Suporta pesos customizados.
    - **Stacking:** Treina um "Meta-Modelo" (ex: Regress√£o Log√≠stica) que aprende a combinar as sa√≠das dos modelos base.

#### 2.4. Otimiza√ß√£o de Hiperpar√¢metros (HPO)
O sistema utiliza **Optuna** como motor de otimiza√ß√£o, oferecendo quatro modos selecion√°veis manualmente:
- **Bayesian Optimization (TPE):** (Padr√£o) Utiliza o estimador *Tree-structured Parzen Estimator* para focar nas √°reas promissoras do espa√ßo de busca. Mais eficiente que Random/Grid.
- **Random Search:** Explora√ß√£o aleat√≥ria do espa√ßo de busca, ideal para benchmarks.
- **Grid Search:** Busca exaustiva em uma grade pr√©-definida. (Implementado via amostragem controlada no Optuna para garantir cobertura).
- **Hyperband:** T√©cnica avan√ßada que descarta configura√ß√µes ruins rapidamente (early stopping agressivo), permitindo testar muito mais combina√ß√µes em menos tempo.

#### 2.5. Presets de Treino (AutoML)
Para agilidade, o sistema oferece perfis pr√©-configurados (`automl_engine.py`):
- **Fast:** ~15 trials. Foca em modelos leves (Logistic Regression, Random Forest) com valida√ß√£o simples. Ideal para testes r√°pidos.
- **Medium:** ~40 trials. Inclui modelos de Gradient Boosting (XGBoost, LightGBM) e valida√ß√£o cruzada mais robusta (CV=5).

#### 2.6. Valida√ß√£o Autom√°tica Inteligente
Define como os modelos s√£o avaliados para evitar *overfitting*. O sistema conta com um modo **Autom√°tico Inteligente**:
- **Autom√°tico (Recomendado):**
    - **S√©ries Temporais:** Detecta automaticamente e aplica `TimeSeriesSplit`.
    - **Pequenos Datasets (<1000 amostras):** Aplica `Cross-Validation` para garantir robustez.
    - **Grandes Datasets (>=1000 amostras):** Aplica `Holdout (Train-Test Split)` para efici√™ncia.
- **Modos Manuais:**
    - **K-Fold Cross Validation**
    - **Stratified K-Fold** (Apenas Classifica√ß√£o)
    - **Holdout**
    - **Time Series Split**

### 3. üëÅÔ∏è Vis√£o Computacional (CV Engine)
O m√≥dulo `cv_engine.py` expande as capacidades para Deep Learning e Vis√£o Computacional:
- **Tarefas Suportadas:**
    - **Classifica√ß√£o de Imagens:** Identifica√ß√£o de classes (ex: Gato vs Cachorro).
    - **Segmenta√ß√£o Sem√¢ntica:** Classifica√ß√£o pixel a pixel (ex: separar fundo e objeto) usando DeepLabV3.
    - **Detec√ß√£o de Objetos:** Localiza√ß√£o com Bounding Boxes usando Faster R-CNN.
- **Modelos & Transfer Learning:**
    - **ResNet18 / ResNet50:** Arquiteturas robustas para classifica√ß√£o geral.
    - **MobileNetV2:** Otimizado para efici√™ncia e dispositivos m√≥veis.
    - **Backbones:** Pesos pr√©-treinados no ImageNet para converg√™ncia r√°pida.

### 4. ‚öñÔ∏è An√°lise de Estabilidade e Robustez
A aba de **Estabilidade** permite avaliar a confiabilidade dos modelos gerados atrav√©s de testes rigorosos:
- **Robustez a Varia√ß√£o de Dados**: Testa o modelo em m√∫ltiplos splits de treino/teste para verificar a consist√™ncia das m√©tricas.
- **Robustez √† Inicializa√ß√£o**: Avalia o impacto de diferentes sementes aleat√≥rias (seeds) no treinamento.
- **Sensibilidade a Hiperpar√¢metros**: Analisa como a performance varia ao alterar um hiperpar√¢metro espec√≠fico.
- **An√°lise Geral**: Executa uma bateria completa de testes e gera um relat√≥rio unificado de estabilidade.

### 5. MLOps, API e Integra√ß√µes
- **MLflow Integration:** Rastreamento completo de experimentos (par√¢metros, m√©tricas, artefatos).
- **DagsHub Connection:**
    - Sincroniza√ß√£o com reposit√≥rios remotos DagsHub.
    - Autentica√ß√£o via Token.
    - Visualiza√ß√£o de status de conex√£o em tempo real.
- **Drift Detection:** Monitoramento de desvio de dados entre treino e produ√ß√£o (Data Drift).
- **Model Registry:** Versionamento e gest√£o de est√°gios de modelos (Staging, Production, Archived).
- **Explicabilidade**: Integra√ß√£o nativa com SHAP.
- **Docker Ready**: Ambiente containerizado pronto para uso.
- **API Serving (FastAPI):**
    - M√≥dulo `api.py` fornece uma interface REST robusta.
    - **Endpoints:** `/predict` para infer√™ncia e `/` para health check.
    - **Seguran√ßa:** Autentica√ß√£o via `x-api-key` no header.
    - **Auto-Reload:** Carrega automaticamente o modelo mais recente salvo em `models/`.

---

## üß† Aprendizados e Decis√µes T√©cnicas

### 1. Flexibilidade com Optuna
Optamos pelo **Optuna** em vez do `GridSearchCV` do Scikit-Learn devido √† sua arquitetura "define-by-run". Isso permitiu:
- Implementar *Bayesian Optimization* facilmente.
- Simular *Grid Search* e *Random Search* apenas alterando o `sampler` (TPESampler, RandomSampler, GridSampler).
- Integrar *Pruning* (Hyperband) para interromper treinos ruins cedo, economizando recursos computacionais.

### 2. Desafios do Grid Search em Espa√ßos Cont√≠nuos
Aprendemos que o *Grid Search* tradicional √© incompat√≠vel com distribui√ß√µes cont√≠nuas (ex: `loguniform` para learning rate).
- **Solu√ß√£o:** Quando o usu√°rio seleciona "Grid Search", o sistema restringe o espa√ßo de busca a um conjunto finito de valores discretos ou reverte para *Random Search* com alta contagem de tentativas se o espa√ßo for muito complexo.

### 3. Valida√ß√£o Autom√°tica Inteligente
Implementamos uma l√≥gica de decis√£o para a valida√ß√£o autom√°tica (`validation_strategy='auto'`):
- **Time Series:** Sempre usa `TimeSeriesSplit`.
- **Dados Pequenos (< 1000 amostras):** Usa `Cross-Validation` (CV) para maior robustez estat√≠stica.
- **Dados Grandes (>= 1000 amostras):** Usa `Holdout` para efici√™ncia computacional, j√° que a vari√¢ncia da estimativa de erro diminui com o volume de dados.

### 4. Persist√™ncia e Estado na Interface (Streamlit)
O Streamlit reexecuta o script a cada intera√ß√£o. Para manter conex√µes (como DagsHub) e configura√ß√µes:
- Usamos `st.session_state` para vari√°veis tempor√°rias.
- Usamos `os.environ` para credenciais e URIs do MLflow, garantindo que o `automl_engine.py` (que roda em outro processo ou contexto) tenha acesso √†s configura√ß√µes definidas na UI.

### 5. Integra√ß√£o H√≠brida MLflow (Local vs Remoto)
- **SQLite (Local):** √ìtimo para desenvolvimento r√°pido e sem internet, mas tem problemas de *locking* com m√∫ltiplas threads.
- **DagsHub (Remoto):** Resolve a colabora√ß√£o e visualiza√ß√£o, mas requer tratamento de erros de rede e autentica√ß√£o.
- **Solu√ß√£o:** Criamos um "switch" na interface que altera dinamicamente a `MLFLOW_TRACKING_URI` e recarrega o cliente MLflow sem precisar reiniciar a aplica√ß√£o.

### 6. Separa√ß√£o de Responsabilidades
- `app.py`: Apenas UI e captura de input.
- `automl_engine.py`: L√≥gica pesada de ML, independente da UI.
- `mlops_utils.py`: Fun√ß√µes utilit√°rias reutiliz√°veis.
Isso facilitou a cria√ß√£o de scripts de teste (`test_interface_simulation.py`) que validam o motor de ML sem precisar clicar na interface.

---

## üìÇ Estrutura do Projeto

- `app.py`: Interface principal (Streamlit Dashboard).
- `automl_engine.py`: Motor de AutoML (Treinamento, Otimiza√ß√£o, Valida√ß√£o).
- `cv_engine.py`: Motor de Vis√£o Computacional.
- `mlops_utils.py`: Utilit√°rios de MLOps.
- `api.py`: API de serving (FastAPI).
- `test_interface_simulation.py`: Script de teste para valida√ß√£o das funcionalidades de otimiza√ß√£o e interface.
- `docker-compose.yml` & `Dockerfile`: Configura√ß√£o de containers.

---

## üöÄ Instala√ß√£o e Uso

### Pr√©-requisitos
- Docker e Docker Compose instalados.
- (Opcional) Python 3.11+ para execu√ß√£o local.

### üê≥ Via Docker (Recomendado)

1. **Clone o reposit√≥rio**:
   ```bash
   git clone <url-do-repositorio>
   cd automlops-studio
   ```

2. **Configure as vari√°veis de ambiente**:
   Copie o exemplo e ajuste conforme necess√°rio (opcional para rodar localmente):
   ```bash
   cp .env.example .env
   ```

3. **Suba os containers**:
   ```bash
   docker-compose up --build
   ```

4. **Acesse os servi√ßos**:
   - **Dashboard (Streamlit)**: [http://localhost:8501](http://localhost:8501)
   - **API (FastAPI)**: [http://localhost:8000](http://localhost:8000)
   - **MLflow UI**: [http://localhost:5000](http://localhost:5000)

### üêç Execu√ß√£o Local (Sem Docker)

1. **Crie um ambiente virtual e instale depend√™ncias**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   venv\Scripts\activate     # Windows
   pip install -r requirements.txt
   ```

2. **Execute o Dashboard**:
   ```bash
   python -m streamlit run app.py
   ```

3. **(Opcional) Execute a API**:
   ```bash
   python -m uvicorn api:app --reload
   ```

### üñ•Ô∏è Aplica√ß√£o Desktop (Electron)

Voc√™ pode executar o projeto como uma aplica√ß√£o desktop h√≠brida (Electron + Python).

1. **Pr√©-requisitos**: Certifique-se de ter o `Node.js` e `npm` instalados.
2. **Instale as depend√™ncias do Electron**:
   ```bash
   npm install
   ```
3. **Inicie em modo de desenvolvimento**:
   ```bash
   npm start
   ```
   Isso iniciar√° o servidor Python em segundo plano e abrir√° a janela do Electron.

4. **Build do Execut√°vel**:
   Para criar um instalador (.exe, .dmg, .AppImage):
   ```bash
   npm run dist
   ```

---

## üß™ Testes e Valida√ß√£o

Para verificar se todas as funcionalidades de otimiza√ß√£o (Grid, Random, Bayesian, Hyperband) e valida√ß√£o autom√°tica est√£o funcionando corretamente, execute o script de simula√ß√£o:

```bash
python test_interface_simulation.py
```
Este script simula o comportamento da interface utilizando os datasets dispon√≠veis no `data_lake`.

---

## üîÆ Pr√≥ximos Passos Sugeridos
*   **Deploy Automatizado:** Gerar containers Docker com o modelo treinado (servindo via API REST/FastAPI) com um clique.
*   **Explainability (XAI):** Adicionar SHAP/LIME na aba de experimentos para explicar as decis√µes dos modelos.
*   **Pipeline de Retreino:** Configurar Jobs agendados para verificar Drift e disparar retreino autom√°tico.

---

**Desenvolvido por Pedro Morato Lahoz.**
