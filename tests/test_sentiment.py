import pandas as pd
import numpy as np
from automl_engine import AutoMLTrainer, AutoMLDataProcessor
from sklearn.metrics import accuracy_score, confusion_matrix
import time

def run_sentiment_test():
    print("ğŸš€ Iniciando teste automatizado com dataset 'sentiment'...")
    
    # 1. Simular carregamento do dataset sentiment
    # Como nÃ£o temos o arquivo fÃ­sico agora, vamos criar um mock que simule o comportamento
    try:
        df = pd.read_csv("data_lake/sentiment/v_20260204_153233.csv")
    except:
        # Fallback para dados sintÃ©ticos se o arquivo nÃ£o existir
        print("âš ï¸ Arquivo nÃ£o encontrado, gerando dados sintÃ©ticos...")
        data = {
            'text': ['bom', 'ruim', 'excelente', 'pessimo', 'legal', 'chato'] * 20,
            'sentiment': [1, 0, 1, 0, 1, 0] * 20
        }
        df = pd.DataFrame(data)
    
    target = 'sentiment'
    
    print(f"ğŸ“Š Dataset criado com {len(df)} linhas. Target: {target}")
    
    # 2. Processamento
    print("âš™ï¸ Processando dados...")
    processor = AutoMLDataProcessor(target_column=target, task_type='classification')
    X, y = processor.fit_transform(df)
    
    # 3. Treinamento AutomÃ¡tico
    print("ğŸ¤– Iniciando AutoML (Modo AutomÃ¡tico)...")
    trainer = AutoMLTrainer(task_type='classification')
    
    def test_callback(trial, score, m_name, dur, metrics=None):
        metrics_str = f" | Metrics: {metrics}" if metrics else ""
        print(f"  âœ¨ Trial {trial.number+1}: {m_name} | Score: {score:.4f} | Tempo: {dur:.2f}s{metrics_str}")

    start_time = time.time()
    # Testando com 2 modelos e 3 trials cada (total 6)
    best_model = trainer.train(
        X, y, 
        n_trials=3, 
        callback=test_callback, 
        selected_models=['logistic_regression', 'random_forest'],
        early_stopping_rounds=5
    )
    
    duration = time.time() - start_time
    print(f"âœ… Treinamento concluÃ­do em {duration:.2f}s")
    
    # 4. AvaliaÃ§Ã£o
    print("ğŸ“Š Avaliando melhor modelo...")
    metrics, y_pred = trainer.evaluate(X, y)
    
    print("\n--- Resultados Finais ---")
    for m_name, m_val in metrics.items():
        if m_name != 'confusion_matrix':
            print(f"ğŸ“ˆ {m_name.upper()}: {m_val:.4f}")
    
    if 'confusion_matrix' in metrics:
        print("ğŸ§© Matriz de ConfusÃ£o:")
        print(np.array(metrics['confusion_matrix']))
    
    print("\n--- VerificaÃ§Ã£o de Erros ---")
    if metrics.get('accuracy', 0) == 0:
        print("âŒ ERRO: A acurÃ¡cia estÃ¡ zerada!")
    elif metrics.get('accuracy', 0) > 0.5:
        print("ğŸ‰ SUCESSO: Modelo aprendeu corretamente.")
    else:
        print("âš ï¸ AVISO: AcurÃ¡cia baixa, mas diferente de zero.")

if __name__ == "__main__":
    run_sentiment_test()
