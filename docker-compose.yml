services:
  # Serviço da API (FastAPI)
  api:
    build: .
    container_name: automl-api
    command: uvicorn api:app --host 0.0.0.0 --port 8000
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - ./mlruns:/app/mlruns
      - ./data_lake:/app/data_lake
      - ./models:/app/models
    env_file:
      - .env
    restart: unless-stopped

  # Serviço do Dashboard (Streamlit)
  dashboard:
    build: .
    container_name: automl-dashboard
    command: python -m streamlit run app.py --server.port=8501 --server.address=0.0.0.0
    ports:
      - "8501:8501"
    volumes:
      - .:/app
      - ./mlruns:/app/mlruns
      - ./data_lake:/app/data_lake
      - ./models:/app/models
    env_file:
      - .env
    depends_on:
      - api
    restart: unless-stopped

  # MLflow UI (Opcional, mas útil para ver experimentos fora do app)
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.2
    container_name: automl-mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    command: mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlruns/mlflow.db --default-artifact-root /mlruns
    restart: unless-stopped
